Title: 1 Million Parameters Are Enough: Merging CNNs and Transformers for Ultra-Lightweight 3D Brain Tumor Segmentation

DOI:待发表

Abstract
Content: 3D medical image segmentation is crucial for brain tumor detection and treatment. Existing deep learning models, such as those based purely on Transformer architectures, excel at global context modeling but typically require a large number of parameters and extensive datasets for effective training. On the other hand, Convolutional Neural Networks (CNNs) possess a strong spatial inductive bias, making them adept at capturing local image features, but they face challenges in establishing global feature dependencies. To address these issues, we propose TransLiteUNet, an ultra-lightweight 3D brain tumor segmentation model that aims to combine the strengths of CNNs and Transformer architectures for efficient and accurate medical image segmentation.

Method: The architecture of TransLiteUNet innovatively incorporates a 3D axial depthwise separable convolutional residual structure, employing 7x7x7 convolution kernels to significantly enlarge the receptive field, thereby capturing more comprehensive spatial features. Additionally, we enhance the Mobile Vision Transformer module as a bottleneck structure to boost the model's capacity for learning complex features while maintaining a low parameter count. To effectively model global features, TransLiteUNet integrates learnable positional encodings. This model does not require pre-training, which greatly simplifies the application process and reduces computational complexity.
In detail, the model architecture consists of multiple stages, each designed to progressively extract and refine features from the input medical images. The initial stage employs standard convolutions to capture local features, followed by the 3D axial depthwise separable convolutional residual blocks to expand the receptive field and enhance feature extraction. The Mobile Vision Transformer modules are strategically placed to act as bottlenecks, enabling the model to efficiently learn and integrate both local and global features. Learnable positional encodings are incorporated to provide spatial information throughout the network, ensuring accurate feature localization and segmentation.

Results: TransLiteUNet demonstrates outstanding performance in five-fold cross-validation experiments on the BraTS2020 and BraTS2021 datasets. On the BraTS2020 test set, the average Dice score is 0.838, with Enhancing Tumor (ET) at 0.764, Tumor Core (TC) at 0.839, and Whole Tumor (WT) at 0.910. For the BraTS2021 test set, the average Dice score is 0.894, with ET at 0.857, TC at 0.893, and WT at 0.932. Compared to current state-of-the-art models, TransLiteUNet exhibits significant advantages in segmentation accuracy. For instance, under the same dataset (BraTS2020) and experimental conditions, CKD-TransBTS achieves an average Dice score of 0.826, nnFormer 0.803, SwinUNETR 0.819, and UNETR 0.812.
    Moreover, TransLiteUNet’s parameter efficiency is noteworthy. It consists of only 442K parameters, which is 102 times fewer than V-Net, 237 times fewer than TransUNet, and 189 times fewer than CKD-TransBTS. This drastic reduction in parameters without sacrificing performance highlights TransLiteUNet’s potential for deployment in resource-constrained environments such as small medical facilities or mobile applications.

Conclusion: TransLiteUNet not only significantly reduces computational complexity but also achieves state-of-the-art performance in 3D brain tumor segmentation tasks. The model's minimal parameter requirement, alongside its high segmentation accuracy, makes it particularly suitable for environments with limited computational resources. Its characteristic of not requiring pre-training further underscores its practicality in clinical settings. By offering detailed implementation codes available at https://github.com/yangyunfeng-cyber/TransLiteUNet , we encourage researchers and practitioners to build upon and enhance this work, fostering further advancements in the field of medical image segmentation.In conclusion, TransLiteUNet represents a significant step forward in the efficient and accurate segmentation of brain tumors, leveraging the combined strengths of CNNs and Transformers. Its lightweight nature and high performance demonstrate its potential for real-world applications, particularly in settings where computational resources are at a premium. The design principles and results proposed in this study can provide some reference for the research and development of future medical image segmentation, and further promote the lightweight research of 3D medical segmentation models.
    
Keywords: Transformer · Encoder-Decoder · Ultra-Lightweight Model · Medical Volumetric Segmentation · TransLiteUNet

